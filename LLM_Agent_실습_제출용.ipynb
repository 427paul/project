{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUTJx_5yJWRd"
      },
      "source": [
        "#Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdSrO6RJT9z"
      },
      "outputs": [],
      "source": [
        "!pip install -U langgraph langchain langchain_openai tavily-python langchain_community chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6x7mODpJd4c"
      },
      "outputs": [],
      "source": [
        "!pip install \"codeinterpreterapi[all]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYpNB_-XJ7Ej"
      },
      "outputs": [],
      "source": [
        "from codeinterpreterapi import CodeInterpreterSession, settings # validation errorê°€ ëœ¬ë‹¤ë©´ ì»¤ë„ì„ ì¬ì‹œì‘ í•œ í›„ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1qkT1x7NGMA"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain langgraph langchain-openai pydot graphviz\n",
        "import os, getpass, warnings; warnings.filterwarnings(\"ignore\")\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsarF_gZNJ1A"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-QzdH6xNXkY"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P34kKDHM9_g"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 1) LLM ì„¤ì •\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPUê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ CPU ì‚¬ìš©\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhNFHIgzPzCc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6GMUtP4MaO4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìë™ ì‚¬ìš©\n",
        ")\n",
        "\n",
        "# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "You are an expert data analyst. Based on your knowledge, answer the following analysis request.\n",
        "\n",
        "Request:\n",
        "{user_query}\n",
        "\n",
        "Please provide an insightful response in fluent English. Use bullet points and clear structure where applicable.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 3. ì²´ì¸ êµ¬ì„±\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    {\"user_query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 4. ì‹¤í–‰ í•¨ìˆ˜\n",
        "def analyze_with_huggingface_model(user_query: str):\n",
        "    print(\"ğŸ“Š ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\\n\")\n",
        "    result = chain.invoke(user_query)\n",
        "    print(\"âœ… ë¶„ì„ ì™„ë£Œ\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    print(result)\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    my_request = (\n",
        "        \"Analyze and visualize the global AI in healthcare market size and growth forecast from 2024 to 2030. \"\n",
        "        \"Create a bar chart comparing the market size of key regions like North America, Europe, and Asia-Pacific for the year 2024.\"\n",
        "    )\n",
        "    analyze_with_huggingface_model(my_request)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAOfcrx8Mj-7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# --- 3. Tavily ì›¹ ê²€ìƒ‰ í•¨ìˆ˜ ---\n",
        "def search_tavily(query: str, max_results: int = 3):\n",
        "    url = \"https://api.tavily.com/search\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"api_key\": os.environ[\"TAVILY_API_KEY\"],\n",
        "        \"query\": query,\n",
        "        \"search_depth\": \"basic\",\n",
        "        \"include_answer\": True,\n",
        "        \"max_results\": max_results,\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"results\" in data:\n",
        "        return [res[\"content\"] for res in data[\"results\"]]\n",
        "    else:\n",
        "        print(\"ê²€ìƒ‰ ì‹¤íŒ¨:\", data)\n",
        "        return []\n",
        "\n",
        "# --- 4. ë¶„ì„ ë° ì‹œê°í™” ìˆ˜í–‰ í•¨ìˆ˜ ---\n",
        "def analyze_and_visualize_with_huggingface(user_query: str, save_dir: str = \"./figures_hf\"):\n",
        "    print(\"ğŸ” Tavilyë¥¼ í†µí•´ ì •ë³´ ê²€ìƒ‰ ì¤‘...\")\n",
        "    search_results = search_tavily(user_query)\n",
        "\n",
        "    if not search_results:\n",
        "        print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    combined_context = \"\\n\\n\".join(search_results[:3])\n",
        "\n",
        "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are a skilled data analyst. Use the following search results to answer the user's query with insight and clarity.\n",
        "\n",
        "    Search Context:\n",
        "    {context}\n",
        "\n",
        "    User Query:\n",
        "    {query}\n",
        "\n",
        "    Please:\n",
        "    - Provide a detailed summary and analysis.\n",
        "    - Then, describe a bar chart to compare market sizes by region for 2024: North America, Europe, and Asia-Pacific.\n",
        "    - Use approximate numbers if exact ones are not available.\n",
        "\n",
        "    Output format:\n",
        "    1. Textual analysis\n",
        "    2. Suggested bar chart data in format: Region: Value\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "    # ì²´ì¸ êµ¬ì„±\n",
        "    chain = (\n",
        "        {\"context\": lambda x: combined_context, \"query\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    print(\"\\nğŸ¤– LLM ë¶„ì„ ì‹œì‘...\\n\")\n",
        "    result_text = chain.invoke(user_query)\n",
        "    print(\"âœ… ë¶„ì„ ê²°ê³¼:\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    print(result_text)\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # ì˜ˆì‹œ: í‚¤ì›Œë“œ ê¸°ë°˜ ì‹œê°í™” ì¡°ê±´ ì²´í¬\n",
        "    if \"bar chart\" in result_text.lower():\n",
        "        print(\"\\nğŸ“Š ë°” ì°¨íŠ¸ ìƒì„± ì¤‘...\")\n",
        "\n",
        "        # ì˜ˆì‹œ ë°ì´í„° (ì‹¤ì œ ë°ì´í„° íŒŒì‹± ë˜ëŠ” ì‚¬ìš©ì ìš”ì²­ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "        labels = ['North America', 'Europe', 'Asia-Pacific']\n",
        "        values = [15.2, 12.3, 18.9]\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        save_path = os.path.join(save_dir, \"ai_healthcare_market_2024.png\")\n",
        "\n",
        "        # ì‹œê°í™” ìƒì„±\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(labels, values, color='skyblue')\n",
        "        plt.title(\"AI in Healthcare Market Size (2024, Example)\")\n",
        "        plt.ylabel(\"Market Size (in Billion USD)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()  # ğŸ‘‰ ì´ ì¤„ ì¶”ê°€ë¡œ í™”ë©´ ì¶œë ¥\n",
        "        plt.close()\n",
        "\n",
        "    else:\n",
        "        print(\"ğŸ“ ì‹œê°í™” ëª…ë ¹ì´ ì—†ê±°ë‚˜ ì¡°ê±´ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# --- 5. ì‹¤í–‰ ì˜ˆì‹œ ---\n",
        "if __name__ == \"__main__\":\n",
        "    my_request = (\n",
        "        \"Analyze and visualize the global AI in healthcare market size and growth forecast from 2024 to 2030. \"\n",
        "        \"Create a bar chart comparing the market size of key regions like North America, Europe, and Asia-Pacific for the year 2024.\"\n",
        "    )\n",
        "    analyze_and_visualize_with_huggingface(my_request)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "\n",
        "# (ìµœì´ˆ 1íšŒ)\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver '/content/drive/MyDrive/Colab Notebooks' #\n",
        "!pip install chromedriver-autoinstaller"
      ],
      "metadata": {
        "id": "j6nOdu9_zRmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "import sys\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import urllib.request\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import chromedriver_autoinstaller  # setup chrome options"
      ],
      "metadata": {
        "id": "RmJb9MUQ0EtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_path = \"/content/drive/MyDrive/Colab Notebooks/chromedriver\"\n",
        "\n",
        "sys.path.insert(0,chrome_path)\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # set path to chromedriver as per your configuration\n",
        "chrome_options.add_argument('lang=ko_KR') # í•œêµ­ì–´\n",
        "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
        "\n",
        "chromedriver_autoinstaller.install()  # set the target URL"
      ],
      "metadata": {
        "id": "ByIciNSH0Iy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "re.findall(\"\\d.*ì›\", \"í• ì¸ê°€ 4,920ì› 2%\")"
      ],
      "metadata": {
        "id": "EWpprEwVXCDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "\n",
        "keyword = \"ìƒí™œ/ì£¼ë°©\"\n",
        "url = f'https://www.gmarket.co.kr/n/best?groupCode={keyword}'#ì£¼ì†Œ\n",
        "res = requests.get(url)#url ì£¼ì†Œì—ì„œ ì •ë³´ ê°€ì ¸ì˜´\n",
        "soup = bs(res.text, 'html.parser')#ì •ë³´ì—ì„œ textì •ë³´ parsing\n",
        "\n",
        "title = [i.text for i in soup.find_all('p', class_='box__item-title')]\n",
        "\n",
        "#selenium driver ë¡œë“œ\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "#ìƒí’ˆ ì •ë³´ë¥¼ ë°›ì„ ë¦¬ìŠ¤íŠ¸\n",
        "prod_info_list = []\n",
        "\n",
        "keyword = \"ìƒí™œ/ì£¼ë°©\"\n",
        "#ë§í¬ ì „ë‹¬\n",
        "driver.get(f\"https://www.gmarket.co.kr/n/best?groupCode={keyword}\")\n",
        "\n",
        "#CSS_SELECTORë¥¼ í™œìš©í•´ì„œ li íƒœê·¸ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°\n",
        "lis = driver.find_elements(By.CSS_SELECTOR, \"li\")\n",
        "\n",
        "#lië“¤ì„ ëŒë©´ì„œ\n",
        "for li in lis:\n",
        "  try: #box__item-title ê°€ì ¸ì˜¤ê¸° ì‹œë„í•˜ëŠ”ë°\n",
        "    itemname = li.find_element(By.CSS_SELECTOR, \"p.box__item-title\")\n",
        "  except: #ì‹¤íŒ¨í•  ê²½ìš°\n",
        "    continue #ë‹¤ìŒ ë£¨í”„ë¡œ ë„˜ì–´ê°\n",
        "\n",
        "  #sale_price ê°€ì ¸ì˜¤ê¸°\n",
        "  sale_price = li.find_element(By.CSS_SELECTOR, \"div.box__price-seller\").text\n",
        "  try:\n",
        "    original_price = li.find_element(By.CSS_SELECTOR, \"div.box__price-original\").text\n",
        "  except:\n",
        "    original_price = \"\"\n",
        "  #prod_info_listì— ìŒ“ê¸°\n",
        "  prod_info_list.append((itemname.text, sale_price, original_price))\n",
        "\n",
        "#driver ì¢…ë£Œ\n",
        "driver.quit()\n",
        "\n",
        "gmarket_df = pd.DataFrame(prod_info_list, columns = ['ìƒí’ˆëª…', 'íŒë§¤ê°€', 'ì›ê°€'])\n",
        "def extract_number(x):\n",
        "    price = re.findall(\"\\d.*ì›\", x) #ìˆ«ìë¡œ ì‹œì‘í•´ì„œ ì›ìœ¼ë¡œ ëë‚˜ëŠ” íŒ¨í„´ì„ ì°¾ê¸°\n",
        "    #ë°ì´í„°ê°€ ë¹ˆ ê²½ìš°ê°€ ìˆìœ¼ë¯€ë¡œ try, exceptë¬¸ ì‚¬ìš©\n",
        "    try:\n",
        "      price_num = price[0].replace(\"ì›\", \"\") #replaceë¡œ ì›ì„ ì œê±°\n",
        "      #ì²œì› ì•„ë˜ ê°€ê²©ë„ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try, exceptë¬¸ ì‚¬ìš©\n",
        "      try:\n",
        "        price_num = int(price_num.replace(\",\", \"\")) #replaceë¡œ ì‰¼í‘œê¹Œì§€ ì œê±°í•˜ê³  intë¡œ ë³€í™˜\n",
        "      except:\n",
        "        price_num = int(price_num) #ì•„ë‹ ê²½ìš° ê·¸ëƒ¥ intë¡œ ë³€í™˜\n",
        "    except:\n",
        "      pass\n",
        "    return price_num if price else None #ë°ì´í„°ê°€ ìˆì„ ê²½ìš° price_numì„ ë°˜í™˜, ì•„ë‹ ê²½ìš° Noneì„ ë°˜í™˜\n",
        "\n",
        "gmarket_df['ì›ê°€'] = gmarket_df['ì›ê°€'].apply(extract_number)\n",
        "\n",
        "gmarket_df['íŒë§¤ê°€'] = gmarket_df['íŒë§¤ê°€'].apply(extract_number)\n",
        "#ê° í–‰ì˜ ì •ê°€ ì—´ì´ naë©´ íŒë§¤ê°€ë¥¼ ëŒ€ì…\n",
        "def fill_na_with_sales(row):\n",
        "    if pd.isna(row['ì›ê°€']):\n",
        "        return row['íŒë§¤ê°€']\n",
        "    else:\n",
        "        return row['ì›ê°€']\n",
        "\n",
        "gmarket_df['ì›ê°€'] = gmarket_df.apply(fill_na_with_sales, axis=1)\n",
        "gmarket_df['ì›ê°€'] = gmarket_df['ì›ê°€'].apply(int)"
      ],
      "metadata": {
        "id": "gjqs8LWmzvOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmarket_df.info()"
      ],
      "metadata": {
        "id": "nehLIiw2WCmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# ìƒ˜í”Œ Gë§ˆì¼“ ë°ì´í„°\n",
        "data = gmarket_df\n",
        "\n",
        "# State ì •ì˜\n",
        "class State(TypedDict):\n",
        "    query: str\n",
        "    result: str\n",
        "\n",
        "# Tool 1: ê°€ê²© ë¶„ì„\n",
        "def price_analysis(query):\n",
        "    avg_price = data['íŒë§¤ê°€'].mean()\n",
        "    discount = ((data['ì›ê°€'] - data['íŒë§¤ê°€']) / data['ì›ê°€'] * 100).mean()\n",
        "    return f\"í‰ê·  ê°€ê²©: {avg_price:,.0f}ì›, í‰ê·  í• ì¸ìœ¨: {discount:.1f}%\"\n",
        "\n",
        "# Tool 2: ìƒí’ˆ ì¶”ì²œ\n",
        "def recommend_products(query):\n",
        "    best_deal = data.loc[((data['ì›ê°€'] - data['íŒë§¤ê°€']) / data['ì›ê°€'] * 100).idxmax()]\n",
        "    return f\"ì¶”ì²œìƒí’ˆ: {best_deal['ìƒí’ˆëª…']} (ê°€ê²©: {best_deal['íŒë§¤ê°€']:,}ì›)\"\n",
        "\n",
        "# Tool 3: ì‹œê°í™”\n",
        "def create_chart(query):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(range(len(data)), data['íŒë§¤ê°€'])\n",
        "    plt.title('Product Prices')\n",
        "    plt.savefig('chart.png')\n",
        "    plt.close()\n",
        "    return \"ì°¨íŠ¸ ì €ì¥ë¨: chart.png\"\n",
        "\n",
        "# Tool 4: ê²€ìƒ‰ (ë”ë¯¸)\n",
        "def web_search(query):\n",
        "    return \"ì£¼ë°©ìš©í’ˆ ì‹œì¥ì€ ì„±ì¥ ì¤‘ì…ë‹ˆë‹¤.\"\n",
        "\n",
        "# ë…¸ë“œ í•¨ìˆ˜ë“¤\n",
        "def analyzer(state: State) -> State:\n",
        "    result1 = price_analysis(state[\"query\"])\n",
        "    result2 = recommend_products(state[\"query\"])\n",
        "    result3 = create_chart(state[\"query\"])\n",
        "    result4 = web_search(state[\"query\"])\n",
        "\n",
        "    state[\"result\"] = f\"{result1}\\n{result2}\\n{result3}\\n{result4}\"\n",
        "    return state\n",
        "\n",
        "def output(state: State) -> State:\n",
        "    print(\"=== ë¶„ì„ ê²°ê³¼ ===\")\n",
        "    print(state[\"result\"])\n",
        "    return state\n",
        "\n",
        "# ê·¸ë˜í”„ ìƒì„±\n",
        "def create_agent():\n",
        "    workflow = StateGraph(State)\n",
        "    workflow.add_node(\"analyze\", analyzer)\n",
        "    workflow.add_node(\"output\", output)\n",
        "\n",
        "    workflow.set_entry_point(\"analyze\")\n",
        "    workflow.add_edge(\"analyze\", \"output\")\n",
        "    workflow.add_edge(\"output\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# ì‹¤í–‰\n",
        "def run_agent(query):\n",
        "    agent = create_agent()\n",
        "    result = agent.invoke({\"query\": query, \"result\": \"\"})\n",
        "    return result\n",
        "\n",
        "# ê·¸ë˜í”„ ì‹œê°í™” (í…ìŠ¤íŠ¸)\n",
        "def show_graph():\n",
        "    print(\"Graph Structure:\")\n",
        "    print(\"User Query -> Analyzer -> Output -> End\")\n",
        "    print(\"Tools: 1.Price Analysis 2.Recommendation 3.Chart 4.Search\")\n",
        "\n",
        "# ì¥ì /ë‹¨ì  ë¶„ì„\n",
        "def analyze_benefits():\n",
        "    print(\"\\n=== ê¸°ì¡´ Chatbot ëŒ€ë¹„ ì¥ì  ===\")\n",
        "    print(\"1. 4ê°œ ë„êµ¬ ë™ì‹œ í™œìš©ìœ¼ë¡œ ì¢…í•© ë¶„ì„\")\n",
        "    print(\"2. êµ¬ì¡°í™”ëœ ì›Œí¬í”Œë¡œìš°ë¡œ ì¼ê´€ëœ ê²°ê³¼\")\n",
        "    print(\"3. ì‹œê°í™” ìë™ ìƒì„±\")\n",
        "\n",
        "    print(\"\\n=== ë¬¸ì œì  ===\")\n",
        "    print(\"1. ëª¨ë“  ë„êµ¬ë¥¼ í•­ìƒ ì‹¤í–‰í•˜ì—¬ ë¹„íš¨ìœ¨ì \")\n",
        "    print(\"2. ë‹¨ê³„ë³„ ì˜¤ë¥˜ ì „íŒŒ ê°€ëŠ¥ì„±\")\n",
        "    print(\"3. ì™¸ë¶€ API ì˜ì¡´ì„±\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    show_graph()\n",
        "    analyze_benefits()\n",
        "    print(\"\\n=== ì‹¤í–‰ ì˜ˆì‹œ ===\")\n",
        "    run_agent(\"ì£¼ë°©ìš©í’ˆ ì¶”ì²œí•´ì£¼ì„¸ìš”\")"
      ],
      "metadata": {
        "id": "Bk5IxmTQzJza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ê³¼ì œ"
      ],
      "metadata": {
        "id": "rmGy7lqTZm7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Gë§ˆì¼“ ìƒ˜í”Œ ë°ì´í„°\n",
        "\n",
        "\n",
        "# HuggingFace LLM ì„¤ì •\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# State ì •ì˜\n",
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    analysis_result: str\n",
        "    search_result: str\n",
        "    chart_result: str\n",
        "    recommendation: str\n",
        "    final_answer: str\n",
        "\n",
        "# Tool 1: ë°ì´í„° ë¶„ì„\n",
        "def analyze_data(state: AgentState) -> AgentState:\n",
        "    # í• ì¸ìœ¨ ê³„ì‚°\n",
        "    discount_rate = ((gmarket_df['ì›ê°€'] - gmarket_df['íŒë§¤ê°€']) / gmarket_df['ì›ê°€'] * 100)\n",
        "    avg_discount = discount_rate.mean()\n",
        "    max_discount_idx = discount_rate.idxmax()\n",
        "    best_deal = gmarket_df.loc[max_discount_idx]\n",
        "\n",
        "    analysis = f\"\"\"\n",
        "    ìƒí’ˆ ë¶„ì„ ê²°ê³¼:\n",
        "    - ì´ ìƒí’ˆ ìˆ˜: {len(gmarket_df)}ê°œ\n",
        "    - í‰ê·  íŒë§¤ê°€: {gmarket_df['íŒë§¤ê°€'].mean():,.0f}ì›\n",
        "    - í‰ê·  í• ì¸ìœ¨: {avg_discount:.1f}%\n",
        "    - ìµœê³  í• ì¸ ìƒí’ˆ: {best_deal['ìƒí’ˆëª…']} ({discount_rate[max_discount_idx]:.1f}% í• ì¸)\n",
        "    \"\"\"\n",
        "\n",
        "    state[\"analysis_result\"] = analysis\n",
        "    return state\n",
        "\n",
        "# Tool 2: ì›¹ ê²€ìƒ‰ (Tavily API ë˜ëŠ” ë”ë¯¸)\n",
        "def web_search(state: AgentState) -> AgentState:\n",
        "    # Tavily API í‚¤ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ê²€ìƒ‰, ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "    if \"TAVILY_API_KEY\" in os.environ:\n",
        "        try:\n",
        "            url = \"https://api.tavily.com/search\"\n",
        "            headers = {\"Content-Type\": \"application/json\"}\n",
        "            payload = {\n",
        "                \"api_key\": os.environ[\"TAVILY_API_KEY\"],\n",
        "                \"query\": f\"kitchen appliances market trends Korea {state['query']}\",\n",
        "                \"search_depth\": \"basic\",\n",
        "                \"max_results\": 2,\n",
        "            }\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            data = response.json()\n",
        "            if \"results\" in data:\n",
        "                search_info = \"\\n\".join([res[\"content\"][:100] for res in data[\"results\"]])\n",
        "            else:\n",
        "                search_info = \"ì£¼ë°©ìš©í’ˆ ì‹œì¥ì€ ì§€ì†ì ìœ¼ë¡œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
        "        except:\n",
        "            search_info = \"ì£¼ë°©ìš©í’ˆ ì‹œì¥ì€ ì§€ì†ì ìœ¼ë¡œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
        "    else:\n",
        "        search_info = \"ì£¼ë°©ìš©í’ˆ ì‹œì¥ì€ ì§€ì†ì ìœ¼ë¡œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìŠ¤í…Œì¸ë¦¬ìŠ¤ ì œí’ˆì´ ì¸ê¸°ê°€ ë†’ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    state[\"search_result\"] = search_info\n",
        "    return state\n",
        "\n",
        "# Tool 3: ì‹œê°í™”\n",
        "def create_visualization(state: AgentState) -> AgentState:\n",
        "    # ê°€ê²© ë¶„í¬ ì°¨íŠ¸ ìƒì„±\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.bar(range(len(gmarket_df)), gmarket_df['íŒë§¤ê°€'], alpha=0.7)\n",
        "    plt.title('Product Sale Prices')\n",
        "    plt.xlabel('Products')\n",
        "    plt.ylabel('Price (KRW)')\n",
        "\n",
        "    # í• ì¸ìœ¨ ì°¨íŠ¸\n",
        "    plt.subplot(1, 2, 2)\n",
        "    discount_rate = ((gmarket_df['ì›ê°€'] - gmarket_df['íŒë§¤ê°€']) / gmarket_df['ì›ê°€'] * 100)\n",
        "    plt.bar(range(len(gmarket_df)), discount_rate, alpha=0.7, color='green')\n",
        "    plt.title('Discount Rates')\n",
        "    plt.xlabel('Products')\n",
        "    plt.ylabel('Discount Rate (%)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig('gmarket_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    state[\"chart_result\"] = \"ì‹œê°í™” ì°¨íŠ¸ê°€ 'gmarket_analysis.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "    return state\n",
        "\n",
        "# Tool 4: ì¶”ì²œ ì‹œìŠ¤í…œ\n",
        "def recommend_products(state: AgentState) -> AgentState:\n",
        "    # í• ì¸ìœ¨ ê¸°ì¤€ ìƒìœ„ 3ê°œ ì¶”ì²œ\n",
        "    discount_rate = ((gmarket_df['ì›ê°€'] - gmarket_df['íŒë§¤ê°€']) / gmarket_df['ì›ê°€'] * 100)\n",
        "    gmarket_df['í• ì¸ìœ¨'] = discount_rate\n",
        "    top_deals = gmarket_df.nlargest(3, 'í• ì¸ìœ¨')\n",
        "\n",
        "    recommendations = \"ì¶”ì²œ ìƒí’ˆ (í• ì¸ìœ¨ ê¸°ì¤€):\\n\"\n",
        "    for idx, row in top_deals.iterrows():\n",
        "        recommendations += f\"- {row['ìƒí’ˆëª…']}: {row['íŒë§¤ê°€']:,}ì› ({row['í• ì¸ìœ¨']:.1f}% í• ì¸)\\n\"\n",
        "\n",
        "    state[\"recommendation\"] = recommendations\n",
        "    return state\n",
        "\n",
        "# LLMì„ ì‚¬ìš©í•œ ìµœì¢… ë¶„ì„\n",
        "def llm_synthesizer(state: AgentState) -> AgentState:\n",
        "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are an expert shopping advisor. Based on the following analysis results, provide comprehensive shopping advice in Korean.\n",
        "\n",
        "    User Query: {query}\n",
        "    Data Analysis: {analysis}\n",
        "    Market Search: {search}\n",
        "    Chart Info: {chart}\n",
        "    Recommendations: {recommendations}\n",
        "\n",
        "    Please provide actionable shopping insights and advice in Korean. Focus on helping the user make informed purchasing decisions.\n",
        "    \"\"\")\n",
        "\n",
        "    # ì²´ì¸ êµ¬ì„±\n",
        "    chain = (\n",
        "        {\n",
        "            \"query\": lambda x: state[\"query\"],\n",
        "            \"analysis\": lambda x: state[\"analysis_result\"],\n",
        "            \"search\": lambda x: state[\"search_result\"],\n",
        "            \"chart\": lambda x: state[\"chart_result\"],\n",
        "            \"recommendations\": lambda x: state[\"recommendation\"]\n",
        "        }\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    # LLM ì‹¤í–‰\n",
        "    final_response = chain.invoke({})\n",
        "    state[\"final_answer\"] = final_response\n",
        "    return state\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "def output_results(state: AgentState) -> AgentState:\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ğŸ›’ Gë§ˆì¼“ ì‡¼í•‘ ë¶„ì„ ê²°ê³¼\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"\\nğŸ“Š ë°ì´í„° ë¶„ì„:\")\n",
        "    print(state[\"analysis_result\"])\n",
        "    print(\"\\nğŸ” ì‹œì¥ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "    print(state[\"search_result\"])\n",
        "    print(\"\\nğŸ“ˆ ì‹œê°í™”:\")\n",
        "    print(state[\"chart_result\"])\n",
        "    print(\"\\nğŸ’¡ ì¶”ì²œ ìƒí’ˆ:\")\n",
        "    print(state[\"recommendation\"])\n",
        "    print(\"\\nğŸ¤– LLM ì¢…í•© ë¶„ì„:\")\n",
        "    print(state[\"final_answer\"])\n",
        "    print(\"=\" * 50)\n",
        "    return state\n",
        "\n",
        "# LangGraph ìƒì„±\n",
        "def create_gmarket_agent():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # ë…¸ë“œ ì¶”ê°€\n",
        "    workflow.add_node(\"analyzer\", analyze_data)\n",
        "    workflow.add_node(\"searcher\", web_search)\n",
        "    workflow.add_node(\"visualizer\", create_visualization)\n",
        "    workflow.add_node(\"recommender\", recommend_products)\n",
        "    workflow.add_node(\"synthesizer\", llm_synthesizer)\n",
        "    workflow.add_node(\"output\", output_results)\n",
        "\n",
        "    # ì—£ì§€ ì„¤ì •\n",
        "    workflow.set_entry_point(\"analyzer\")\n",
        "    workflow.add_edge(\"analyzer\", \"searcher\")\n",
        "    workflow.add_edge(\"searcher\", \"visualizer\")\n",
        "    workflow.add_edge(\"visualizer\", \"recommender\")\n",
        "    workflow.add_edge(\"recommender\", \"synthesizer\")\n",
        "    workflow.add_edge(\"synthesizer\", \"output\")\n",
        "    workflow.add_edge(\"output\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# ì‹¤í–‰ í•¨ìˆ˜\n",
        "def run_agent(query: str):\n",
        "    agent = create_gmarket_agent()\n",
        "\n",
        "    initial_state = {\n",
        "        \"query\": query,\n",
        "        \"analysis_result\": \"\",\n",
        "        \"search_result\": \"\",\n",
        "        \"chart_result\": \"\",\n",
        "        \"recommendation\": \"\",\n",
        "        \"final_answer\": \"\"\n",
        "    }\n",
        "\n",
        "    print(f\"ğŸš€ ì‚¬ìš©ì ìš”ì²­: {query}\")\n",
        "    result = agent.invoke(initial_state)\n",
        "    return result\n",
        "\n",
        "# ê·¸ë˜í”„ ì‹œê°í™” (í…ìŠ¤íŠ¸)\n",
        "def show_graph_structure():\n",
        "    print(\"\\nğŸ“‹ LangGraph êµ¬ì¡°:\")\n",
        "    print(\"User Query â†’ Data Analyzer â†’ Web Searcher â†’ Visualizer â†’ Recommender â†’ LLM Synthesizer â†’ Output â†’ End\")\n",
        "    print(\"\\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬ë“¤:\")\n",
        "    print(\"1. Data Analysis Tool: ê°€ê²© ë¶„ì„, í• ì¸ìœ¨ ê³„ì‚°\")\n",
        "    print(\"2. Web Search Tool: Tavily APIë¡œ ì‹œì¥ íŠ¸ë Œë“œ ê²€ìƒ‰\")\n",
        "    print(\"3. Visualization Tool: matplotlibìœ¼ë¡œ ì°¨íŠ¸ ìƒì„±\")\n",
        "    print(\"4. Recommendation Tool: í• ì¸ìœ¨ ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ\")\n",
        "    print(\"5. LLM Synthesizer: HuggingFace ëª¨ë¸ë¡œ ì¢…í•© ë¶„ì„\")\n",
        "\n",
        "# ì¥ì /ë‹¨ì  ë¶„ì„\n",
        "def analyze_agent_performance():\n",
        "    print(\"\\nğŸš€ ê¸°ì¡´ Chatbot ëŒ€ë¹„ ì¥ì :\")\n",
        "    print(\"- ë‹¤ë‹¨ê³„ ë¶„ì„: ë°ì´í„°ë¶„ì„â†’ê²€ìƒ‰â†’ì‹œê°í™”â†’ì¶”ì²œâ†’LLMì¢…í•©ì˜ ì²´ê³„ì  í”„ë¡œì„¸ìŠ¤\")\n",
        "    print(\"- ë„êµ¬ ì¡°í•©: 5ê°œ ë„êµ¬ë¥¼ ì—°ê³„í•˜ì—¬ ì¢…í•©ì  ì‡¼í•‘ ì¡°ì–¸ ì œê³µ\")\n",
        "    print(\"- ì‹¤ì‹œê°„ ì •ë³´: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì‹œì¥ íŠ¸ë Œë“œ ë°˜ì˜\")\n",
        "    print(\"- ì‹œê°ì  ë¶„ì„: ìë™ ì°¨íŠ¸ ìƒì„±ìœ¼ë¡œ ì§ê´€ì  ì •ë³´ ì œê³µ\")\n",
        "\n",
        "    print(\"\\nâš ï¸ ë¬¸ì œì :\")\n",
        "    print(\"- ì²˜ë¦¬ ì‹œê°„: ìˆœì°¨ì  ì‹¤í–‰ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ ì¦ê°€\")\n",
        "    print(\"- ì˜¤ë¥˜ ì „íŒŒ: í•œ ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜í–¥\")\n",
        "    print(\"- ë³µì¡ì„±: ê°„ë‹¨í•œ ì§ˆë¬¸ì—ë„ ëª¨ë“  ë‹¨ê³„ ì‹¤í–‰\")\n",
        "    print(\"- API ì˜ì¡´: ì™¸ë¶€ ì„œë¹„ìŠ¤ ì¥ì•  ì‹œ ê¸°ëŠ¥ ì œí•œ\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ê·¸ë˜í”„ êµ¬ì¡° ì¶œë ¥\n",
        "    show_graph_structure()\n",
        "\n",
        "    # ì„±ëŠ¥ ë¶„ì„ ì¶œë ¥\n",
        "    analyze_agent_performance()\n",
        "\n",
        "    # ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ğŸ›’ Gë§ˆì¼“ LLM Agent ì‹¤í–‰ ì˜ˆì‹œ\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "    result = run_agent(\"í• ì¸ìœ¨ì´ ë†’ì€ ì£¼ë°©ìš©í’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”\")"
      ],
      "metadata": {
        "id": "osvT4fCoXja7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UmnTcNrYS0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}