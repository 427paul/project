{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dodcl09ZGFqH"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain langgraph langchain-openai pydot graphviz\n",
        "import os, getpass, warnings; warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PromptTemplate"
      ],
      "metadata": {
        "id": "l1_lIop3GUS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Say hello to {name} in Korean. Answer only in Korean.\")\n",
        "print(\"템플릿 변수:\", prompt.input_variables)\n",
        "print(prompt.format(name=\"Alice\"))\n"
      ],
      "metadata": {
        "id": "P3VQjFDCGIlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM"
      ],
      "metadata": {
        "id": "o8A6CkkhGaPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "BWnS9S2BGS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "F2kPDRDKGffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPU가 없으면 자동으로 CPU 사용\n",
        ")\n",
        "\n",
        "# 사용법은 동일합니다.\n",
        "print(\"LangChain 파이프라인으로 모델을 호출합니다...\")\n",
        "response = llm.invoke(\"LangChain에 대해 한 문장으로 설명해줘.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "jVpRhV_8Gkk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chain"
      ],
      "metadata": {
        "id": "VdTnOp0-Ned4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 1) LLM 설정\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPU가 없으면 자동으로 CPU 사용\n",
        ")\n",
        "\n",
        "# 2) 감정 분석용 프롬프트 템플릿\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"다음 문장의 감정(sentiment)을 분석하고, -1.0(매우 부정)부터 +1.0(매우 긍정) 사이의 부동소수점 점수와 간단한 라벨('positive', 'neutral', 'negative')을\"\n",
        "    \" 다음 형식으로 출력하세요:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"문장: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "# 3) 체인 조합 (템플릿 → LLM)\n",
        "# 문자열 파서가 없으면 생성 응답 외의 메타데이터도 다 출력된다.\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# 4) 실행 예시\n",
        "result = chain.invoke({\n",
        "    \"text\": \"오늘 날씨는 참 좋지만, 지하철이 너무 붐벼서 힘들었어요.\"\n",
        "})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "KlQFcl2rGx5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 1) LLM 설정\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPU가 없으면 자동으로 CPU 사용\n",
        ")\n",
        "\n",
        "# 2) 감정 분석용 프롬프트 템플릿\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"다음 문장의 감정(sentiment)을 분석하고, -1.0(매우 부정)부터 +1.0(매우 긍정) 사이의 부동소수점 점수와 간단한 라벨('positive', 'neutral', 'negative')을\"\n",
        "    \" 다음 형식으로 출력하세요:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"문장: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "# 3) 체인 조합 (템플릿 → LLM → 문자열 파서)\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 4) 실행 예시\n",
        "result = chain.invoke({\n",
        "    \"text\": \"오늘 날씨는 참 좋지만, 지하철이 너무 붐벼서 힘들었어요.\"\n",
        "})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3CnCZ_g7NvlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#프로젝트"
      ],
      "metadata": {
        "id": "2xZgixcSPIXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기초 준비"
      ],
      "metadata": {
        "id": "_kblCsk6PLuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리들을 가져옵니다.\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- LLM 및 감정 분석 체인 설정 ---\n",
        "\n",
        "# LLM을 초기화합니다.\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"mrm8488/t5-base-finetuned-emotion\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 10,\n",
        "        \"temperature\": 0.5,\n",
        "    },\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "# LLM에게 어떤 작업을 시킬지 프롬프트로 정의합니다.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"다음 문장의 감정을 분석하세요. 결과는 다음 형식을 따르세요:\\n\"\n",
        "    \"SCORE: <숫자: -1.0(매우 부정) ~ +1.0(매우 긍정)>\\n\"\n",
        "    \"LABEL: <positive|neutral|negative>\\n\\n\"\n",
        "    \"예시:\\n\"\n",
        "    \"문장: \\\"이 제품은 정말 마음에 들어요.\\\"\\n\"\n",
        "    \"SCORE: 0.9\\n\"\n",
        "    \"LABEL: positive\\n\\n\"\n",
        "    \"문장: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# 프롬프트, LLM, 출력 파서를 파이프라인처럼 연결하여 '체인'을 만듭니다.\n",
        "sentiment_analysis_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"✅ 1단계: 기초 준비 완료!\")"
      ],
      "metadata": {
        "id": "N6gABI8cOLm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상태(state)"
      ],
      "metadata": {
        "id": "BzeiMsXNPQbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프의 상태(State) 구조를 정의합니다.\n",
        "# 각 노드를 거치면서 이 상태 객체에 데이터가 채워지고 수정됩니다.\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str      # 사용자가 입력한 원본 문장\n",
        "    sentiment_score: float # LLM이 분석한 감정 점수\n",
        "    sentiment_label: str   # LLM이 분석한 감정 라벨 ('positive', 'neutral', 'negative')\n",
        "\n",
        "print(\"✅ 2단계: 상태 정의 완료!\")"
      ],
      "metadata": {
        "id": "c9dtbNnlPPl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "노드(node)"
      ],
      "metadata": {
        "id": "E94Id8uKPUkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 감정 분석을 수행하는 메인 노드\n",
        "def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "    print(\"\\n--- [노드 실행] 감정 분석 시작 ---\")\n",
        "    user_text = state[\"user_input\"]\n",
        "\n",
        "    # LLM 호출\n",
        "    result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "    print(f\"LLM 분석 결과:\\n{result_str}\")\n",
        "\n",
        "    # 모델이 출력한 감정 라벨 (예: \"joy\") 에서 긍/부/중립 라벨로 매핑\n",
        "    label_map = {\n",
        "        \"joy\": \"positive\",\n",
        "        \"love\": \"positive\",\n",
        "        \"surprise\": \"positive\",\n",
        "        \"anger\": \"negative\",\n",
        "        \"sadness\": \"negative\",\n",
        "        \"fear\": \"negative\",\n",
        "    }\n",
        "\n",
        "    label_raw = result_str.strip().lower()\n",
        "    mapped_label = label_map.get(label_raw, \"neutral\")\n",
        "\n",
        "    # 상태 업데이트\n",
        "    state[\"sentiment_score\"] = 0.0  # 점수는 없는 모델이므로 기본값 사용\n",
        "    state[\"sentiment_label\"] = mapped_label\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# 2. 각 결과에 따라 간단한 메시지를 출력하는 노드들\n",
        "def positive_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 긍정적인 반응 ---\")\n",
        "    print(\"😀 긍정적인 내용이네요! 좋은 하루 보내세요.\")\n",
        "\n",
        "def neutral_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 중립적인 반응 ---\")\n",
        "    print(\"😐 중립적인 내용이군요. 알려주셔서 감사합니다.\")\n",
        "\n",
        "def negative_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 부정적인 반응 ---\")\n",
        "    print(\"😟 부정적인 경험을 하셨군요. 괜찮으신가요?\")\n",
        "\n",
        "print(\"✅ 3단계: 노드 정의 완료!\")"
      ],
      "metadata": {
        "id": "d74G1ZwhPTpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 구성 및 엣지(Edge) 연결"
      ],
      "metadata": {
        "id": "8_xE4upRPX7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프의 흐름을 결정하는 라우팅(routing) 함수\n",
        "def route_by_sentiment(state: GraphState) -> str:\n",
        "    \"\"\"상태의 sentiment_label을 보고 다음 노드의 이름을 반환합니다.\"\"\"\n",
        "    label = state[\"sentiment_label\"]\n",
        "    print(f\"\\n--- [분기] '{label}' 라벨에 따라 다음 경로 결정 ---\")\n",
        "    return label\n",
        "\n",
        "# --- 그래프 설계 시작 ---\n",
        "\n",
        "# 1. 상태(State) 모델을 기반으로 그래프 객체를 생성합니다.\n",
        "g = StateGraph(GraphState)\n",
        "\n",
        "# 2. 그래프에 노드들을 추가합니다. (이름, 실행할 함수)\n",
        "g.add_node(\"analyze_sentiment\", analyze_sentiment_node)\n",
        "g.add_node(\"positive_path\", positive_node)\n",
        "g.add_node(\"neutral_path\", neutral_node)\n",
        "g.add_node(\"negative_path\", negative_node)\n",
        "\n",
        "# 3. 진입점(Entry Point)을 설정합니다.\n",
        "g.set_entry_point(\"analyze_sentiment\")\n",
        "\n",
        "# 4. 조건부 엣지(Conditional Edge)를 추가합니다.\n",
        "# 'analyze_sentiment' 노드가 끝난 후, 'route_by_sentiment' 함수의 결과에 따라 다음 노드로 분기합니다.\n",
        "g.add_conditional_edges(\n",
        "    \"analyze_sentiment\", #start_node_name\n",
        "    route_by_sentiment, #path_decider\n",
        "    path_map={\n",
        "        \"positive\": \"positive_path\",\n",
        "        \"neutral\": \"neutral_path\",\n",
        "        \"negative\": \"negative_path\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 5. 각 분기 노드에서 작업이 끝나면 그래프를 종료(END)하도록 엣지를 추가합니다.\n",
        "g.add_edge(\"positive_path\", END)\n",
        "g.add_edge(\"neutral_path\", END)\n",
        "g.add_edge(\"negative_path\", END)\n",
        "\n",
        "print(\"✅ 4단계: 그래프 설계 완료!\")"
      ],
      "metadata": {
        "id": "Q_Rnyq38PWpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 컴파일 및 호출"
      ],
      "metadata": {
        "id": "WUrxsvXqPcHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 컴파일\n",
        "graph = g.compile()\n",
        "\n",
        "# 실행할 문장\n",
        "input_text = \"오늘 날씨는 참 좋지만, 지하철이 너무 붐벼서 힘들었어요.\"\n",
        "\n",
        "# 그래프 실행\n",
        "final_state = graph.invoke({\"user_input\": input_text})\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"✅ 5단계: 그래프 실행 완료!\")\n",
        "print(\"최종 상태:\", final_state)"
      ],
      "metadata": {
        "id": "7Vkb_m_xPa3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리들을 가져옵니다.\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- LLM 및 감정 분석 체인 설정 ---\n",
        "\n",
        "# LLM을 초기화합니다.\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"mrm8488/t5-base-finetuned-emotion\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 10,\n",
        "        \"temperature\": 0.5,\n",
        "    },\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "rRtYWJbRS7Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM에게 어떤 작업을 시킬지 프롬프트로 정의합니다.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"다음 문장의 감정(sentiment)을 분석하고, -1.0(매우 부정)부터 +1.0(매우 긍정) 사이의 점수와 \"\n",
        "    \"라벨('positive', 'neutral', 'negative')을 다음 형식으로 출력하세요:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"문장: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# 프롬프트, LLM, 출력 파서를 파이프라인처럼 연결하여 '체인'을 만듭니다.\n",
        "sentiment_analysis_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"✅ 1단계: 기초 준비 완료!\")"
      ],
      "metadata": {
        "id": "uYUFgF9QTte_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프의 상태(State) 구조를 정의합니다.\n",
        "# 각 노드를 거치면서 이 상태 객체에 데이터가 채워지고 수정됩니다.\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str      # 사용자가 입력한 원본 문장\n",
        "    sentiment_score: float # LLM이 분석한 감정 점수\n",
        "    sentiment_label: str   # LLM이 분석한 감정 라벨 ('positive', 'neutral', 'negative')\n",
        "\n",
        "print(\"✅ 2단계: 상태 정의 완료!\")\n",
        "\n",
        "\n",
        "# 1. 감정 분석을 수행하는 메인 노드\n",
        "# def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "#     print(\"\\n--- [노드 실행] 감정 분석 시작 ---\")\n",
        "#     user_text = state[\"user_input\"]\n",
        "\n",
        "#     # LLM 호출\n",
        "#     result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "#     print(f\"LLM 분석 결과:\\n{result_str}\")\n",
        "\n",
        "#     # 모델이 출력한 감정 라벨 (예: \"joy\") 에서 긍/부/중립 라벨로 매핑\n",
        "#     label_map = {\n",
        "#         \"joy\": \"positive\",\n",
        "#         \"love\": \"positive\",\n",
        "#         \"surprise\": \"positive\",\n",
        "#         \"anger\": \"negative\",\n",
        "#         \"sadness\": \"negative\",\n",
        "#         \"fear\": \"negative\",\n",
        "#     }\n",
        "\n",
        "#     label_raw = result_str.strip().lower()\n",
        "#     mapped_label = label_map.get(label_raw, \"neutral\")\n",
        "\n",
        "#     # 상태 업데이트\n",
        "#     state[\"sentiment_score\"] = 0.0  # 점수는 없는 모델이므로 기본값 사용\n",
        "#     state[\"sentiment_label\"] = mapped_label\n",
        "\n",
        "#     return state\n",
        "\n",
        "def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "    print(\"\\n--- [노드 실행] 감정 분석 시작 ---\")\n",
        "    user_text = state[\"user_input\"]\n",
        "\n",
        "    result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "    print(f\"LLM 분석 결과:\\n{result_str}\")\n",
        "\n",
        "    # 점수와 라벨 초기화\n",
        "    score = 0.0\n",
        "    label = \"neutral\"\n",
        "\n",
        "    try:\n",
        "        parsed_output = {}\n",
        "        for line in result_str.strip().split(\"\\n\"):\n",
        "            if \":\" in line:\n",
        "                key, value = line.split(\":\", 1)\n",
        "                parsed_output[key.strip().upper()] = value.strip()\n",
        "\n",
        "        # SCORE와 LABEL이 모두 존재할 때만 사용\n",
        "        if \"SCORE\" in parsed_output and \"LABEL\" in parsed_output:\n",
        "            score = float(parsed_output[\"SCORE\"])\n",
        "            label = parsed_output[\"LABEL\"].lower()\n",
        "    except Exception as e:\n",
        "        print(f\"[파싱 오류] {e}, 기본값 사용\")\n",
        "\n",
        "    state[\"sentiment_score\"] = score\n",
        "    state[\"sentiment_label\"] = label\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# 2. 각 결과에 따라 간단한 메시지를 출력하는 노드들\n",
        "def positive_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 긍정적인 반응 ---\")\n",
        "    print(\"😀 긍정적인 내용이네요! 좋은 하루 보내세요.\")\n",
        "\n",
        "def neutral_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 중립적인 반응 ---\")\n",
        "    print(\"😐 중립적인 내용이군요. 알려주셔서 감사합니다.\")\n",
        "\n",
        "def negative_node(state: GraphState):\n",
        "    print(\"--- [노드 실행] 부정적인 반응 ---\")\n",
        "    print(\"😟 부정적인 경험을 하셨군요. 괜찮으신가요?\")\n",
        "\n",
        "print(\"✅ 3단계: 노드 정의 완료!\")\n",
        "\n",
        "\n",
        "# 그래프의 흐름을 결정하는 라우팅(routing) 함수\n",
        "def route_by_sentiment(state: GraphState) -> str:\n",
        "    \"\"\"상태의 sentiment_label을 보고 다음 노드의 이름을 반환합니다.\"\"\"\n",
        "    label = state[\"sentiment_label\"]\n",
        "    print(f\"\\n--- [분기] '{label}' 라벨에 따라 다음 경로 결정 ---\")\n",
        "    return label\n",
        "\n",
        "# --- 그래프 설계 시작 ---\n",
        "\n",
        "# 1. 상태(State) 모델을 기반으로 그래프 객체를 생성합니다.\n",
        "g = StateGraph(GraphState)\n",
        "\n",
        "# 2. 그래프에 노드들을 추가합니다. (이름, 실행할 함수)\n",
        "g.add_node(\"analyze_sentiment\", analyze_sentiment_node)\n",
        "g.add_node(\"positive_path\", positive_node)\n",
        "g.add_node(\"neutral_path\", neutral_node)\n",
        "g.add_node(\"negative_path\", negative_node)\n",
        "\n",
        "# 3. 진입점(Entry Point)을 설정합니다.\n",
        "g.set_entry_point(\"analyze_sentiment\")\n",
        "\n",
        "# 4. 조건부 엣지(Conditional Edge)를 추가합니다.\n",
        "# 'analyze_sentiment' 노드가 끝난 후, 'route_by_sentiment' 함수의 결과에 따라 다음 노드로 분기합니다.\n",
        "g.add_conditional_edges(\n",
        "    \"analyze_sentiment\", #start_node_name\n",
        "    route_by_sentiment, #path_decider\n",
        "    path_map={\n",
        "        \"positive\": \"positive_path\",\n",
        "        \"neutral\": \"neutral_path\",\n",
        "        \"negative\": \"negative_path\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 5. 각 분기 노드에서 작업이 끝나면 그래프를 종료(END)하도록 엣지를 추가합니다.\n",
        "g.add_edge(\"positive_path\", END)\n",
        "g.add_edge(\"neutral_path\", END)\n",
        "g.add_edge(\"negative_path\", END)\n",
        "\n",
        "print(\"✅ 4단계: 그래프 설계 완료!\")"
      ],
      "metadata": {
        "id": "i31Ly4IjPdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 컴파일\n",
        "graph = g.compile()\n",
        "\n",
        "# 실행할 문장\n",
        "input_text = \"오늘 날씨는 참 좋지만, 지하철이 너무 붐벼서 힘들었어요.\"\n",
        "\n",
        "# 그래프 실행\n",
        "final_state = graph.invoke({\"user_input\": input_text})\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"✅ 5단계: 그래프 실행 완료!\")\n",
        "print(\"최종 상태:\", final_state)"
      ],
      "metadata": {
        "id": "h5lg66veTV8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 구조 출력하기(grandalf, mermaid)"
      ],
      "metadata": {
        "id": "G5ZFIFqTUgib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf"
      ],
      "metadata": {
        "id": "RrLSppg8TXaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grandalf\n",
        "\n",
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "id": "Mv4BQm39UjuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mermaid 포맷의 코드를 생성합니다.\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ],
      "metadata": {
        "id": "zkq81inSVCQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#과제"
      ],
      "metadata": {
        "id": "K4KAobIKZy4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community transformers"
      ],
      "metadata": {
        "id": "UgPuZLmOZ-1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. 모델 준비 및 래핑\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "    top_k=1\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=sentiment_pipeline)\n",
        "\n",
        "# 2. PromptTemplate 사용 (채점 기준 만족)\n",
        "prompt = PromptTemplate.from_template(\"Analyze the emotion of the following input:\\n{text}\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 3. 상태 정의 (채점 기준 만족)\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str\n",
        "    sentiment_label: str\n",
        "    recommended_news: str\n",
        "\n",
        "# 4. 노드 정의 (채점 기준 만족)\n",
        "\n",
        "# 감정 분석 노드\n",
        "def analyze_sentiment(state: GraphState) -> GraphState:\n",
        "    print(\"\\n[분석 중] 사용자 입력:\", state[\"user_input\"])\n",
        "    outputs = sentiment_pipeline(state[\"user_input\"])\n",
        "    print(\"파이프라인 출력:\", outputs)\n",
        "\n",
        "    # 중첩 리스트 방지\n",
        "    result = outputs[0][0] if isinstance(outputs[0], list) else outputs[0]\n",
        "    label = result[\"label\"].lower()\n",
        "    print(\"예측 감정:\", label)\n",
        "\n",
        "    # 감정 라벨을 positive/neutral/negative로 매핑\n",
        "    label_map = {\n",
        "        \"positive\": \"positive\",\n",
        "        \"neutral\": \"neutral\",\n",
        "        \"negative\": \"negative\",\n",
        "        \"joy\": \"positive\",\n",
        "        \"love\": \"positive\",\n",
        "        \"surprise\": \"positive\",\n",
        "        \"anger\": \"negative\",\n",
        "        \"sadness\": \"negative\",\n",
        "        \"fear\": \"negative\"\n",
        "    }\n",
        "    mapped_label = label_map.get(label, \"neutral\")\n",
        "    state[\"sentiment_label\"] = mapped_label\n",
        "    return state\n",
        "\n",
        "\n",
        "# 감정에 따른 뉴스 추천 노드들\n",
        "def recommend_positive_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"✨ 오늘의 긍정 뉴스: 과학 기술의 발전으로 암 치료법이 새롭게 개발되었습니다!\"\n",
        "    return state\n",
        "\n",
        "def recommend_neutral_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"📊 오늘의 정보 뉴스: 미국의 기준금리가 0.25%p 인상되었습니다.\"\n",
        "    return state\n",
        "\n",
        "def recommend_negative_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"🌿 힐링 뉴스: 제주 바다의 돌고래 떼가 다시 돌아왔습니다.\"\n",
        "    return state\n",
        "\n",
        "# 5. 조건부 분기 (채점 기준 만족)\n",
        "def route_sentiment(state: GraphState) -> str:\n",
        "    return state[\"sentiment_label\"]\n",
        "\n",
        "# 6. 그래프 구성\n",
        "graph_builder = StateGraph(GraphState)\n",
        "graph_builder.set_entry_point(\"analyze\")\n",
        "graph_builder.add_node(\"analyze\", analyze_sentiment)\n",
        "graph_builder.add_node(\"positive_news\", recommend_positive_news)\n",
        "graph_builder.add_node(\"neutral_news\", recommend_neutral_news)\n",
        "graph_builder.add_node(\"negative_news\", recommend_negative_news)\n",
        "\n",
        "# 조건부 경로 추가\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"analyze\",\n",
        "    route_sentiment,\n",
        "    {\n",
        "        \"positive\": \"positive_news\",\n",
        "        \"neutral\": \"neutral_news\",\n",
        "        \"negative\": \"negative_news\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 종료 처리\n",
        "graph_builder.add_edge(\"positive_news\", END)\n",
        "graph_builder.add_edge(\"neutral_news\", END)\n",
        "graph_builder.add_edge(\"negative_news\", END)\n",
        "\n",
        "# 그래프 컴파일\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# 실행 예시\n",
        "user_text = \"오늘은 정말 기분이 좋고 뿌듯한 하루였어요.\"\n",
        "result_state = graph.invoke({\"user_input\": user_text})\n",
        "\n",
        "print(\"\\n🎯 감정 라벨:\", result_state[\"sentiment_label\"])\n",
        "print(\"📰 추천 뉴스:\", result_state[\"recommended_news\"])\n"
      ],
      "metadata": {
        "id": "VvG156MjWsDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grandalf\n",
        "\n",
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "id": "M7_jxY_nZ38P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ],
      "metadata": {
        "id": "4QrV09dubQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1puJyHbVbSSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}