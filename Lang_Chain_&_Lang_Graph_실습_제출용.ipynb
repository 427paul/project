{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dodcl09ZGFqH"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain langgraph langchain-openai pydot graphviz\n",
        "import os, getpass, warnings; warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PromptTemplate"
      ],
      "metadata": {
        "id": "l1_lIop3GUS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Say hello to {name} in Korean. Answer only in Korean.\")\n",
        "print(\"í…œí”Œë¦¿ ë³€ìˆ˜:\", prompt.input_variables)\n",
        "print(prompt.format(name=\"Alice\"))\n"
      ],
      "metadata": {
        "id": "P3VQjFDCGIlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM"
      ],
      "metadata": {
        "id": "o8A6CkkhGaPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "BWnS9S2BGS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "F2kPDRDKGffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPUê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ CPU ì‚¬ìš©\n",
        ")\n",
        "\n",
        "# ì‚¬ìš©ë²•ì€ ë™ì¼í•©ë‹ˆë‹¤.\n",
        "print(\"LangChain íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤...\")\n",
        "response = llm.invoke(\"LangChainì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "jVpRhV_8Gkk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chain"
      ],
      "metadata": {
        "id": "VdTnOp0-Ned4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 1) LLM ì„¤ì •\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPUê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ CPU ì‚¬ìš©\n",
        ")\n",
        "\n",
        "# 2) ê°ì • ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •(sentiment)ì„ ë¶„ì„í•˜ê³ , -1.0(ë§¤ìš° ë¶€ì •)ë¶€í„° +1.0(ë§¤ìš° ê¸ì •) ì‚¬ì´ì˜ ë¶€ë™ì†Œìˆ˜ì  ì ìˆ˜ì™€ ê°„ë‹¨í•œ ë¼ë²¨('positive', 'neutral', 'negative')ì„\"\n",
        "    \" ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"ë¬¸ì¥: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "# 3) ì²´ì¸ ì¡°í•© (í…œí”Œë¦¿ â†’ LLM)\n",
        "# ë¬¸ìì—´ íŒŒì„œê°€ ì—†ìœ¼ë©´ ìƒì„± ì‘ë‹µ ì™¸ì˜ ë©”íƒ€ë°ì´í„°ë„ ë‹¤ ì¶œë ¥ëœë‹¤.\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# 4) ì‹¤í–‰ ì˜ˆì‹œ\n",
        "result = chain.invoke({\n",
        "    \"text\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì°¸ ì¢‹ì§€ë§Œ, ì§€í•˜ì² ì´ ë„ˆë¬´ ë¶ë²¼ì„œ í˜ë“¤ì—ˆì–´ìš”.\"\n",
        "})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "KlQFcl2rGx5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 1) LLM ì„¤ì •\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"google/flan-t5-base\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    device_map=\"auto\",  # GPUê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ CPU ì‚¬ìš©\n",
        ")\n",
        "\n",
        "# 2) ê°ì • ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •(sentiment)ì„ ë¶„ì„í•˜ê³ , -1.0(ë§¤ìš° ë¶€ì •)ë¶€í„° +1.0(ë§¤ìš° ê¸ì •) ì‚¬ì´ì˜ ë¶€ë™ì†Œìˆ˜ì  ì ìˆ˜ì™€ ê°„ë‹¨í•œ ë¼ë²¨('positive', 'neutral', 'negative')ì„\"\n",
        "    \" ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"ë¬¸ì¥: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "# 3) ì²´ì¸ ì¡°í•© (í…œí”Œë¦¿ â†’ LLM â†’ ë¬¸ìì—´ íŒŒì„œ)\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 4) ì‹¤í–‰ ì˜ˆì‹œ\n",
        "result = chain.invoke({\n",
        "    \"text\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì°¸ ì¢‹ì§€ë§Œ, ì§€í•˜ì² ì´ ë„ˆë¬´ ë¶ë²¼ì„œ í˜ë“¤ì—ˆì–´ìš”.\"\n",
        "})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3CnCZ_g7NvlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#í”„ë¡œì íŠ¸"
      ],
      "metadata": {
        "id": "2xZgixcSPIXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê¸°ì´ˆ ì¤€ë¹„"
      ],
      "metadata": {
        "id": "_kblCsk6PLuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- LLM ë° ê°ì • ë¶„ì„ ì²´ì¸ ì„¤ì • ---\n",
        "\n",
        "# LLMì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"mrm8488/t5-base-finetuned-emotion\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 10,\n",
        "        \"temperature\": 0.5,\n",
        "    },\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "# LLMì—ê²Œ ì–´ë–¤ ì‘ì—…ì„ ì‹œí‚¬ì§€ í”„ë¡¬í”„íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•˜ì„¸ìš”. ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:\\n\"\n",
        "    \"SCORE: <ìˆ«ì: -1.0(ë§¤ìš° ë¶€ì •) ~ +1.0(ë§¤ìš° ê¸ì •)>\\n\"\n",
        "    \"LABEL: <positive|neutral|negative>\\n\\n\"\n",
        "    \"ì˜ˆì‹œ:\\n\"\n",
        "    \"ë¬¸ì¥: \\\"ì´ ì œí’ˆì€ ì •ë§ ë§ˆìŒì— ë“¤ì–´ìš”.\\\"\\n\"\n",
        "    \"SCORE: 0.9\\n\"\n",
        "    \"LABEL: positive\\n\\n\"\n",
        "    \"ë¬¸ì¥: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸, LLM, ì¶œë ¥ íŒŒì„œë¥¼ íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì—°ê²°í•˜ì—¬ 'ì²´ì¸'ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "sentiment_analysis_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"âœ… 1ë‹¨ê³„: ê¸°ì´ˆ ì¤€ë¹„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "N6gABI8cOLm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìƒíƒœ(state)"
      ],
      "metadata": {
        "id": "BzeiMsXNPQbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ì˜ ìƒíƒœ(State) êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "# ê° ë…¸ë“œë¥¼ ê±°ì¹˜ë©´ì„œ ì´ ìƒíƒœ ê°ì²´ì— ë°ì´í„°ê°€ ì±„ì›Œì§€ê³  ìˆ˜ì •ë©ë‹ˆë‹¤.\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str      # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì›ë³¸ ë¬¸ì¥\n",
        "    sentiment_score: float # LLMì´ ë¶„ì„í•œ ê°ì • ì ìˆ˜\n",
        "    sentiment_label: str   # LLMì´ ë¶„ì„í•œ ê°ì • ë¼ë²¨ ('positive', 'neutral', 'negative')\n",
        "\n",
        "print(\"âœ… 2ë‹¨ê³„: ìƒíƒœ ì •ì˜ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "c9dtbNnlPPl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë…¸ë“œ(node)"
      ],
      "metadata": {
        "id": "E94Id8uKPUkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ ë…¸ë“œ\n",
        "def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "    print(\"\\n--- [ë…¸ë“œ ì‹¤í–‰] ê°ì • ë¶„ì„ ì‹œì‘ ---\")\n",
        "    user_text = state[\"user_input\"]\n",
        "\n",
        "    # LLM í˜¸ì¶œ\n",
        "    result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "    print(f\"LLM ë¶„ì„ ê²°ê³¼:\\n{result_str}\")\n",
        "\n",
        "    # ëª¨ë¸ì´ ì¶œë ¥í•œ ê°ì • ë¼ë²¨ (ì˜ˆ: \"joy\") ì—ì„œ ê¸/ë¶€/ì¤‘ë¦½ ë¼ë²¨ë¡œ ë§¤í•‘\n",
        "    label_map = {\n",
        "        \"joy\": \"positive\",\n",
        "        \"love\": \"positive\",\n",
        "        \"surprise\": \"positive\",\n",
        "        \"anger\": \"negative\",\n",
        "        \"sadness\": \"negative\",\n",
        "        \"fear\": \"negative\",\n",
        "    }\n",
        "\n",
        "    label_raw = result_str.strip().lower()\n",
        "    mapped_label = label_map.get(label_raw, \"neutral\")\n",
        "\n",
        "    # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
        "    state[\"sentiment_score\"] = 0.0  # ì ìˆ˜ëŠ” ì—†ëŠ” ëª¨ë¸ì´ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
        "    state[\"sentiment_label\"] = mapped_label\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# 2. ê° ê²°ê³¼ì— ë”°ë¼ ê°„ë‹¨í•œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ë…¸ë“œë“¤\n",
        "def positive_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ê¸ì •ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜€ ê¸ì •ì ì¸ ë‚´ìš©ì´ë„¤ìš”! ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”.\")\n",
        "\n",
        "def neutral_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ì¤‘ë¦½ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜ ì¤‘ë¦½ì ì¸ ë‚´ìš©ì´êµ°ìš”. ì•Œë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "def negative_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ë¶€ì •ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜Ÿ ë¶€ì •ì ì¸ ê²½í—˜ì„ í•˜ì…¨êµ°ìš”. ê´œì°®ìœ¼ì‹ ê°€ìš”?\")\n",
        "\n",
        "print(\"âœ… 3ë‹¨ê³„: ë…¸ë“œ ì •ì˜ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "d74G1ZwhPTpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê·¸ë˜í”„ êµ¬ì„± ë° ì—£ì§€(Edge) ì—°ê²°"
      ],
      "metadata": {
        "id": "8_xE4upRPX7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ì˜ íë¦„ì„ ê²°ì •í•˜ëŠ” ë¼ìš°íŒ…(routing) í•¨ìˆ˜\n",
        "def route_by_sentiment(state: GraphState) -> str:\n",
        "    \"\"\"ìƒíƒœì˜ sentiment_labelì„ ë³´ê³  ë‹¤ìŒ ë…¸ë“œì˜ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    label = state[\"sentiment_label\"]\n",
        "    print(f\"\\n--- [ë¶„ê¸°] '{label}' ë¼ë²¨ì— ë”°ë¼ ë‹¤ìŒ ê²½ë¡œ ê²°ì • ---\")\n",
        "    return label\n",
        "\n",
        "# --- ê·¸ë˜í”„ ì„¤ê³„ ì‹œì‘ ---\n",
        "\n",
        "# 1. ìƒíƒœ(State) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "g = StateGraph(GraphState)\n",
        "\n",
        "# 2. ê·¸ë˜í”„ì— ë…¸ë“œë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤. (ì´ë¦„, ì‹¤í–‰í•  í•¨ìˆ˜)\n",
        "g.add_node(\"analyze_sentiment\", analyze_sentiment_node)\n",
        "g.add_node(\"positive_path\", positive_node)\n",
        "g.add_node(\"neutral_path\", neutral_node)\n",
        "g.add_node(\"negative_path\", negative_node)\n",
        "\n",
        "# 3. ì§„ì…ì (Entry Point)ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "g.set_entry_point(\"analyze_sentiment\")\n",
        "\n",
        "# 4. ì¡°ê±´ë¶€ ì—£ì§€(Conditional Edge)ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "# 'analyze_sentiment' ë…¸ë“œê°€ ëë‚œ í›„, 'route_by_sentiment' í•¨ìˆ˜ì˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤.\n",
        "g.add_conditional_edges(\n",
        "    \"analyze_sentiment\", #start_node_name\n",
        "    route_by_sentiment, #path_decider\n",
        "    path_map={\n",
        "        \"positive\": \"positive_path\",\n",
        "        \"neutral\": \"neutral_path\",\n",
        "        \"negative\": \"negative_path\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 5. ê° ë¶„ê¸° ë…¸ë“œì—ì„œ ì‘ì—…ì´ ëë‚˜ë©´ ê·¸ë˜í”„ë¥¼ ì¢…ë£Œ(END)í•˜ë„ë¡ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "g.add_edge(\"positive_path\", END)\n",
        "g.add_edge(\"neutral_path\", END)\n",
        "g.add_edge(\"negative_path\", END)\n",
        "\n",
        "print(\"âœ… 4ë‹¨ê³„: ê·¸ë˜í”„ ì„¤ê³„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "Q_Rnyq38PWpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê·¸ë˜í”„ ì»´íŒŒì¼ ë° í˜¸ì¶œ"
      ],
      "metadata": {
        "id": "WUrxsvXqPcHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
        "graph = g.compile()\n",
        "\n",
        "# ì‹¤í–‰í•  ë¬¸ì¥\n",
        "input_text = \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì°¸ ì¢‹ì§€ë§Œ, ì§€í•˜ì² ì´ ë„ˆë¬´ ë¶ë²¼ì„œ í˜ë“¤ì—ˆì–´ìš”.\"\n",
        "\n",
        "# ê·¸ë˜í”„ ì‹¤í–‰\n",
        "final_state = graph.invoke({\"user_input\": input_text})\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"âœ… 5ë‹¨ê³„: ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "print(\"ìµœì¢… ìƒíƒœ:\", final_state)"
      ],
      "metadata": {
        "id": "7Vkb_m_xPa3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- LLM ë° ê°ì • ë¶„ì„ ì²´ì¸ ì„¤ì • ---\n",
        "\n",
        "# LLMì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"mrm8488/t5-base-finetuned-emotion\",\n",
        "    task=\"text2text-generation\",\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 10,\n",
        "        \"temperature\": 0.5,\n",
        "    },\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "rRtYWJbRS7Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMì—ê²Œ ì–´ë–¤ ì‘ì—…ì„ ì‹œí‚¬ì§€ í”„ë¡¬í”„íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •(sentiment)ì„ ë¶„ì„í•˜ê³ , -1.0(ë§¤ìš° ë¶€ì •)ë¶€í„° +1.0(ë§¤ìš° ê¸ì •) ì‚¬ì´ì˜ ì ìˆ˜ì™€ \"\n",
        "    \"ë¼ë²¨('positive', 'neutral', 'negative')ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\\n\"\n",
        "    \"SCORE: <score>\\n\"\n",
        "    \"LABEL: <label>\\n\\n\"\n",
        "    \"ë¬¸ì¥: \\\"{text}\\\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸, LLM, ì¶œë ¥ íŒŒì„œë¥¼ íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì—°ê²°í•˜ì—¬ 'ì²´ì¸'ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "sentiment_analysis_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"âœ… 1ë‹¨ê³„: ê¸°ì´ˆ ì¤€ë¹„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "uYUFgF9QTte_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ì˜ ìƒíƒœ(State) êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "# ê° ë…¸ë“œë¥¼ ê±°ì¹˜ë©´ì„œ ì´ ìƒíƒœ ê°ì²´ì— ë°ì´í„°ê°€ ì±„ì›Œì§€ê³  ìˆ˜ì •ë©ë‹ˆë‹¤.\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str      # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì›ë³¸ ë¬¸ì¥\n",
        "    sentiment_score: float # LLMì´ ë¶„ì„í•œ ê°ì • ì ìˆ˜\n",
        "    sentiment_label: str   # LLMì´ ë¶„ì„í•œ ê°ì • ë¼ë²¨ ('positive', 'neutral', 'negative')\n",
        "\n",
        "print(\"âœ… 2ë‹¨ê³„: ìƒíƒœ ì •ì˜ ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "# 1. ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ ë…¸ë“œ\n",
        "# def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "#     print(\"\\n--- [ë…¸ë“œ ì‹¤í–‰] ê°ì • ë¶„ì„ ì‹œì‘ ---\")\n",
        "#     user_text = state[\"user_input\"]\n",
        "\n",
        "#     # LLM í˜¸ì¶œ\n",
        "#     result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "#     print(f\"LLM ë¶„ì„ ê²°ê³¼:\\n{result_str}\")\n",
        "\n",
        "#     # ëª¨ë¸ì´ ì¶œë ¥í•œ ê°ì • ë¼ë²¨ (ì˜ˆ: \"joy\") ì—ì„œ ê¸/ë¶€/ì¤‘ë¦½ ë¼ë²¨ë¡œ ë§¤í•‘\n",
        "#     label_map = {\n",
        "#         \"joy\": \"positive\",\n",
        "#         \"love\": \"positive\",\n",
        "#         \"surprise\": \"positive\",\n",
        "#         \"anger\": \"negative\",\n",
        "#         \"sadness\": \"negative\",\n",
        "#         \"fear\": \"negative\",\n",
        "#     }\n",
        "\n",
        "#     label_raw = result_str.strip().lower()\n",
        "#     mapped_label = label_map.get(label_raw, \"neutral\")\n",
        "\n",
        "#     # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
        "#     state[\"sentiment_score\"] = 0.0  # ì ìˆ˜ëŠ” ì—†ëŠ” ëª¨ë¸ì´ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
        "#     state[\"sentiment_label\"] = mapped_label\n",
        "\n",
        "#     return state\n",
        "\n",
        "def analyze_sentiment_node(state: GraphState) -> GraphState:\n",
        "    print(\"\\n--- [ë…¸ë“œ ì‹¤í–‰] ê°ì • ë¶„ì„ ì‹œì‘ ---\")\n",
        "    user_text = state[\"user_input\"]\n",
        "\n",
        "    result_str = sentiment_analysis_chain.invoke({\"text\": user_text})\n",
        "    print(f\"LLM ë¶„ì„ ê²°ê³¼:\\n{result_str}\")\n",
        "\n",
        "    # ì ìˆ˜ì™€ ë¼ë²¨ ì´ˆê¸°í™”\n",
        "    score = 0.0\n",
        "    label = \"neutral\"\n",
        "\n",
        "    try:\n",
        "        parsed_output = {}\n",
        "        for line in result_str.strip().split(\"\\n\"):\n",
        "            if \":\" in line:\n",
        "                key, value = line.split(\":\", 1)\n",
        "                parsed_output[key.strip().upper()] = value.strip()\n",
        "\n",
        "        # SCOREì™€ LABELì´ ëª¨ë‘ ì¡´ì¬í•  ë•Œë§Œ ì‚¬ìš©\n",
        "        if \"SCORE\" in parsed_output and \"LABEL\" in parsed_output:\n",
        "            score = float(parsed_output[\"SCORE\"])\n",
        "            label = parsed_output[\"LABEL\"].lower()\n",
        "    except Exception as e:\n",
        "        print(f\"[íŒŒì‹± ì˜¤ë¥˜] {e}, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
        "\n",
        "    state[\"sentiment_score\"] = score\n",
        "    state[\"sentiment_label\"] = label\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# 2. ê° ê²°ê³¼ì— ë”°ë¼ ê°„ë‹¨í•œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ë…¸ë“œë“¤\n",
        "def positive_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ê¸ì •ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜€ ê¸ì •ì ì¸ ë‚´ìš©ì´ë„¤ìš”! ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”.\")\n",
        "\n",
        "def neutral_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ì¤‘ë¦½ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜ ì¤‘ë¦½ì ì¸ ë‚´ìš©ì´êµ°ìš”. ì•Œë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "def negative_node(state: GraphState):\n",
        "    print(\"--- [ë…¸ë“œ ì‹¤í–‰] ë¶€ì •ì ì¸ ë°˜ì‘ ---\")\n",
        "    print(\"ğŸ˜Ÿ ë¶€ì •ì ì¸ ê²½í—˜ì„ í•˜ì…¨êµ°ìš”. ê´œì°®ìœ¼ì‹ ê°€ìš”?\")\n",
        "\n",
        "print(\"âœ… 3ë‹¨ê³„: ë…¸ë“œ ì •ì˜ ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "# ê·¸ë˜í”„ì˜ íë¦„ì„ ê²°ì •í•˜ëŠ” ë¼ìš°íŒ…(routing) í•¨ìˆ˜\n",
        "def route_by_sentiment(state: GraphState) -> str:\n",
        "    \"\"\"ìƒíƒœì˜ sentiment_labelì„ ë³´ê³  ë‹¤ìŒ ë…¸ë“œì˜ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    label = state[\"sentiment_label\"]\n",
        "    print(f\"\\n--- [ë¶„ê¸°] '{label}' ë¼ë²¨ì— ë”°ë¼ ë‹¤ìŒ ê²½ë¡œ ê²°ì • ---\")\n",
        "    return label\n",
        "\n",
        "# --- ê·¸ë˜í”„ ì„¤ê³„ ì‹œì‘ ---\n",
        "\n",
        "# 1. ìƒíƒœ(State) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "g = StateGraph(GraphState)\n",
        "\n",
        "# 2. ê·¸ë˜í”„ì— ë…¸ë“œë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤. (ì´ë¦„, ì‹¤í–‰í•  í•¨ìˆ˜)\n",
        "g.add_node(\"analyze_sentiment\", analyze_sentiment_node)\n",
        "g.add_node(\"positive_path\", positive_node)\n",
        "g.add_node(\"neutral_path\", neutral_node)\n",
        "g.add_node(\"negative_path\", negative_node)\n",
        "\n",
        "# 3. ì§„ì…ì (Entry Point)ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "g.set_entry_point(\"analyze_sentiment\")\n",
        "\n",
        "# 4. ì¡°ê±´ë¶€ ì—£ì§€(Conditional Edge)ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "# 'analyze_sentiment' ë…¸ë“œê°€ ëë‚œ í›„, 'route_by_sentiment' í•¨ìˆ˜ì˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤.\n",
        "g.add_conditional_edges(\n",
        "    \"analyze_sentiment\", #start_node_name\n",
        "    route_by_sentiment, #path_decider\n",
        "    path_map={\n",
        "        \"positive\": \"positive_path\",\n",
        "        \"neutral\": \"neutral_path\",\n",
        "        \"negative\": \"negative_path\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 5. ê° ë¶„ê¸° ë…¸ë“œì—ì„œ ì‘ì—…ì´ ëë‚˜ë©´ ê·¸ë˜í”„ë¥¼ ì¢…ë£Œ(END)í•˜ë„ë¡ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "g.add_edge(\"positive_path\", END)\n",
        "g.add_edge(\"neutral_path\", END)\n",
        "g.add_edge(\"negative_path\", END)\n",
        "\n",
        "print(\"âœ… 4ë‹¨ê³„: ê·¸ë˜í”„ ì„¤ê³„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "i31Ly4IjPdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
        "graph = g.compile()\n",
        "\n",
        "# ì‹¤í–‰í•  ë¬¸ì¥\n",
        "input_text = \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì°¸ ì¢‹ì§€ë§Œ, ì§€í•˜ì² ì´ ë„ˆë¬´ ë¶ë²¼ì„œ í˜ë“¤ì—ˆì–´ìš”.\"\n",
        "\n",
        "# ê·¸ë˜í”„ ì‹¤í–‰\n",
        "final_state = graph.invoke({\"user_input\": input_text})\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"âœ… 5ë‹¨ê³„: ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "print(\"ìµœì¢… ìƒíƒœ:\", final_state)"
      ],
      "metadata": {
        "id": "h5lg66veTV8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê·¸ë˜í”„ êµ¬ì¡° ì¶œë ¥í•˜ê¸°(grandalf, mermaid)"
      ],
      "metadata": {
        "id": "G5ZFIFqTUgib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf"
      ],
      "metadata": {
        "id": "RrLSppg8TXaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grandalf\n",
        "\n",
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "id": "Mv4BQm39UjuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mermaid í¬ë§·ì˜ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ],
      "metadata": {
        "id": "zkq81inSVCQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ê³¼ì œ"
      ],
      "metadata": {
        "id": "K4KAobIKZy4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community transformers"
      ],
      "metadata": {
        "id": "UgPuZLmOZ-1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. ëª¨ë¸ ì¤€ë¹„ ë° ë˜í•‘\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "    top_k=1\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=sentiment_pipeline)\n",
        "\n",
        "# 2. PromptTemplate ì‚¬ìš© (ì±„ì  ê¸°ì¤€ ë§Œì¡±)\n",
        "prompt = PromptTemplate.from_template(\"Analyze the emotion of the following input:\\n{text}\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 3. ìƒíƒœ ì •ì˜ (ì±„ì  ê¸°ì¤€ ë§Œì¡±)\n",
        "class GraphState(TypedDict):\n",
        "    user_input: str\n",
        "    sentiment_label: str\n",
        "    recommended_news: str\n",
        "\n",
        "# 4. ë…¸ë“œ ì •ì˜ (ì±„ì  ê¸°ì¤€ ë§Œì¡±)\n",
        "\n",
        "# ê°ì • ë¶„ì„ ë…¸ë“œ\n",
        "def analyze_sentiment(state: GraphState) -> GraphState:\n",
        "    print(\"\\n[ë¶„ì„ ì¤‘] ì‚¬ìš©ì ì…ë ¥:\", state[\"user_input\"])\n",
        "    outputs = sentiment_pipeline(state[\"user_input\"])\n",
        "    print(\"íŒŒì´í”„ë¼ì¸ ì¶œë ¥:\", outputs)\n",
        "\n",
        "    # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë°©ì§€\n",
        "    result = outputs[0][0] if isinstance(outputs[0], list) else outputs[0]\n",
        "    label = result[\"label\"].lower()\n",
        "    print(\"ì˜ˆì¸¡ ê°ì •:\", label)\n",
        "\n",
        "    # ê°ì • ë¼ë²¨ì„ positive/neutral/negativeë¡œ ë§¤í•‘\n",
        "    label_map = {\n",
        "        \"positive\": \"positive\",\n",
        "        \"neutral\": \"neutral\",\n",
        "        \"negative\": \"negative\",\n",
        "        \"joy\": \"positive\",\n",
        "        \"love\": \"positive\",\n",
        "        \"surprise\": \"positive\",\n",
        "        \"anger\": \"negative\",\n",
        "        \"sadness\": \"negative\",\n",
        "        \"fear\": \"negative\"\n",
        "    }\n",
        "    mapped_label = label_map.get(label, \"neutral\")\n",
        "    state[\"sentiment_label\"] = mapped_label\n",
        "    return state\n",
        "\n",
        "\n",
        "# ê°ì •ì— ë”°ë¥¸ ë‰´ìŠ¤ ì¶”ì²œ ë…¸ë“œë“¤\n",
        "def recommend_positive_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"âœ¨ ì˜¤ëŠ˜ì˜ ê¸ì • ë‰´ìŠ¤: ê³¼í•™ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ì•” ì¹˜ë£Œë²•ì´ ìƒˆë¡­ê²Œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤!\"\n",
        "    return state\n",
        "\n",
        "def recommend_neutral_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"ğŸ“Š ì˜¤ëŠ˜ì˜ ì •ë³´ ë‰´ìŠ¤: ë¯¸êµ­ì˜ ê¸°ì¤€ê¸ˆë¦¬ê°€ 0.25%p ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "    return state\n",
        "\n",
        "def recommend_negative_news(state: GraphState) -> GraphState:\n",
        "    state[\"recommended_news\"] = \"ğŸŒ¿ íë§ ë‰´ìŠ¤: ì œì£¼ ë°”ë‹¤ì˜ ëŒê³ ë˜ ë–¼ê°€ ë‹¤ì‹œ ëŒì•„ì™”ìŠµë‹ˆë‹¤.\"\n",
        "    return state\n",
        "\n",
        "# 5. ì¡°ê±´ë¶€ ë¶„ê¸° (ì±„ì  ê¸°ì¤€ ë§Œì¡±)\n",
        "def route_sentiment(state: GraphState) -> str:\n",
        "    return state[\"sentiment_label\"]\n",
        "\n",
        "# 6. ê·¸ë˜í”„ êµ¬ì„±\n",
        "graph_builder = StateGraph(GraphState)\n",
        "graph_builder.set_entry_point(\"analyze\")\n",
        "graph_builder.add_node(\"analyze\", analyze_sentiment)\n",
        "graph_builder.add_node(\"positive_news\", recommend_positive_news)\n",
        "graph_builder.add_node(\"neutral_news\", recommend_neutral_news)\n",
        "graph_builder.add_node(\"negative_news\", recommend_negative_news)\n",
        "\n",
        "# ì¡°ê±´ë¶€ ê²½ë¡œ ì¶”ê°€\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"analyze\",\n",
        "    route_sentiment,\n",
        "    {\n",
        "        \"positive\": \"positive_news\",\n",
        "        \"neutral\": \"neutral_news\",\n",
        "        \"negative\": \"negative_news\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# ì¢…ë£Œ ì²˜ë¦¬\n",
        "graph_builder.add_edge(\"positive_news\", END)\n",
        "graph_builder.add_edge(\"neutral_news\", END)\n",
        "graph_builder.add_edge(\"negative_news\", END)\n",
        "\n",
        "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# ì‹¤í–‰ ì˜ˆì‹œ\n",
        "user_text = \"ì˜¤ëŠ˜ì€ ì •ë§ ê¸°ë¶„ì´ ì¢‹ê³  ë¿Œë“¯í•œ í•˜ë£¨ì˜€ì–´ìš”.\"\n",
        "result_state = graph.invoke({\"user_input\": user_text})\n",
        "\n",
        "print(\"\\nğŸ¯ ê°ì • ë¼ë²¨:\", result_state[\"sentiment_label\"])\n",
        "print(\"ğŸ“° ì¶”ì²œ ë‰´ìŠ¤:\", result_state[\"recommended_news\"])\n"
      ],
      "metadata": {
        "id": "VvG156MjWsDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import grandalf\n",
        "\n",
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "id": "M7_jxY_nZ38P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ],
      "metadata": {
        "id": "4QrV09dubQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1puJyHbVbSSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}